import cv2
from ultralytics import YOLO
import os

# Configuration
VIDEO_PATH = "data/videos/surveillance.mp4"
OUTPUT_PATH = "results/videos/output_tracking.mp4"

def track_objects():
    print(f"üïµÔ∏è  D√©marrage du Tracking sur : {VIDEO_PATH}")
    
    if not os.path.exists(VIDEO_PATH):
        raise FileNotFoundError(f"‚ùå Vid√©o introuvable.")

    # Chargement du mod√®le
    model = YOLO('yolov8n.pt')

    cap = cv2.VideoCapture(VIDEO_PATH)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    out = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

    print("‚ñ∂Ô∏è Tracking en cours... (Regarde les num√©ros au-dessus des t√™tes)")

    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break

        # üîß C'EST ICI QUE LA MAGIE OP√àRE : persist=True
        # Cela active le tracking (l'IA se "souvient" des images pr√©c√©dentes)
        results = model.track(frame, persist=True, conf=0.5, classes=0, verbose=False)

        # R√©cup√©ration de l'image annot√©e par YOLO
        annotated_frame = results[0].plot()

        # Bonus : On peut r√©cup√©rer les IDs manuellement si on veut faire des stats
        if results[0].boxes.id is not None:
            # R√©cup√®re les IDs uniques pr√©sents sur l'image
            track_ids = results[0].boxes.id.int().cpu().tolist()
            # On pourrait afficher ici : "Personnes d√©tect√©es : ID 1, ID 2..."

        cv2.imshow("Tracking - IDs Uniques", annotated_frame)
        out.write(annotated_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"\n‚úÖ Tracking termin√© ! Vid√©o sauvegard√©e dans : {OUTPUT_PATH}")

if __name__ == "__main__":
    track_objects()